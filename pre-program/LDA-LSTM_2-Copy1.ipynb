{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件  hotel_description_small.csv 存在。盛宴大幕拉开了。\n",
      "段落处理完毕\n",
      "文件  stopwords.txt 存在。盛宴大幕拉开了。\n",
      "段落处理完毕\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "#jieba.posseg是分词器  ”我爱北京天安门“会变成我 r    爱 v    北京 ns    天安门 ns\n",
    "import jieba.posseg as jp, jieba\n",
    "import reader\n",
    "import numpy as np\n",
    "# 文本集\n",
    "# file_name = 'select_description_from_sys_district.csv'\n",
    "file_name = 'hotel_description_small.csv'\n",
    "if reader.check_file(file_name, url=''):\n",
    "    hotelsDesc = reader.read_data_as_array(file_name)\n",
    "else:\n",
    "    quit()\n",
    "texts = hotelsDesc # 生成格式如下\n",
    "# print(hotelsDesc)\n",
    "# texts = [\n",
    "#     '美国教练坦言，没输给中国女排，是输给了郎平',\n",
    "#     '美国无缘四强，听听主教练的评价',\n",
    "#     '中国女排晋级世锦赛四强，全面解析主教练郎平的执教艺术',\n",
    "#     '为什么越来越多的人买MPV，而放弃SUV？跑一趟长途就知道了',\n",
    "#     '跑了长途才知道，SUV和轿车之间的差距',\n",
    "#     '家用的轿车买什么好']\n",
    "# 分词过滤条件\n",
    "# jieba.add_word('一方天地', 9, 'n')\n",
    "# n\t普通名词\tf\t方位名词\ts\t处所名词\tt\t时间名词\n",
    "# nr\t人名\tns\t地名\tnt\t机构团体名\tnw\t作品名\n",
    "# nz\t其他专名\tv\t普通动词\tvd\t动副词\tvn\t名动词\n",
    "# a\t形容词\tad\t副形词\tan\t名形词\td\t副词\n",
    "# m\t数量词\tq\t量词\tr\t代词\tp\t介词\n",
    "# c\t连词\tu\t助词\txc\t其他虚词\tw\t\n",
    "# PER\t人名\tLOC\t地名\tORG\t机构名\tTIME\t时间\n",
    "flags = ('n', 'f', 's', 't', 'nr', 'ns', 'nt', 'nw', 'nz','v','vd','vn','a','ad','an','d','q','r','p','c','u','xc','PER','LOC','ORG')  # 词性\n",
    "stop_file_name = 'stopwords.txt'\n",
    "if reader.check_file(stop_file_name, url=''):\n",
    "    stopWords = reader.read_data_as_array(stop_file_name)\n",
    "else:\n",
    "    quit()\n",
    "\n",
    "stopword_list = set(stopWords)  # 停词。格式为{'', '她', '无', '至', '前后', '即令', '大', '往', '不特', '有的', '替代',。。。}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.976 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---{}, {} ['开业', '间房', '上海', '时生隅', '园林', '文化', '酒店', '秋末', '时生隅', '初见', '心愿', '想要', '快节奏', '都市', '讲诉', '时光', '生命', '角落', '对错', '闻', '浮沉', '便是', '时生隅', '由来', '秉承', '初心', '川沙', '地铁站', '商圈', '觅得', '天地', '充满', '江南', '气息', '园林', '叶园', '长廊', '湖景', '古雅', '庭院', '大气', '快节奏', '民俗文化', '交融', '幽静', '明快', '小憩', '居', '别样', '天地', '时生隅', '新老朋友', '叶园', '期待', '共', '当下', '时光', '言欢'] 58\n",
      "---{}, {} ['n', 'n', 'ns', 'n', 'n', 'n', 'n', 't', 'n', 'v', 'n', 'v', 'n', 'ns', 'v', 'n', 'vn', 'n', 'v', 'v', 'a', 'v', 'n', 'c', 'v', 'n', 'ns', 'n', 'n', 'v', 'n', 'a', 'ns', 'n', 'n', 'nr', 'n', 'n', 'nr', 'n', 'n', 'n', 'n', 'n', 'a', 'a', 'nr', 'v', 'r', 'n', 'n', 'n', 'nr', 'v', 'd', 't', 'n', 'nr'] 58\n",
      "---{}, {} ['开业', '装修', '间', '房云', '夜泊', '酒店', '上海浦东国际机场', '店', '位于', '浦东新区', '祝桥秋亭', '路', '毗邻', '上海浦东国际机场', '车程', '分钟', '上海', '迪士尼', '分钟', '车程', '上海', '动物园', '分钟', '车程', '酒店', '地理位置', '优越', '配备', '大巴', '中巴', '豪华轿车', '接送', '客户', '酒店', '拥有', '房间', '床', '间', '行政', '大床', '间', '标间', '间亲', '子房', '间'] 45\n",
      "---{}, {} ['n', 'v', 'f', 'n', 'n', 'n', 'nt', 'n', 'v', 'ns', 'nr', 'n', 'v', 'nt', 'n', 'q', 'ns', 'nr', 'q', 'n', 'ns', 'n', 'q', 'n', 'n', 'n', 'a', 'v', 'n', 'ns', 'n', 'v', 'n', 'n', 'v', 'n', 'n', 'f', 'n', 'n', 'f', 'n', 'n', 'n', 'f'] 45\n",
      "---{}, {} ['开业', '装修', '间房', '维也纳', '酒店', '上海浦东', '机场', '店', '位于', '浦东新区', '川南', '奉', '公路', '近晨', '阳路', '迪士尼', '直线', '距离', '约', '公里', '便捷', '到达', '地铁', '号线', '凌空', '路站', '交通', '便利', '酒店', '周围', '生活', '设施', '齐全', '旅游', '资源', '上海', '新', '国际博览', '中心', '迪士尼', '上海', '动物园', '农艺', '大观园', '滨海', '旅游区', '维也纳', '酒店', '上海浦东', '机场', '店', '维也纳', '旗下', '连锁', '酒店', '装修', '豪华', '舒适', '整体', '风格', '高贵典雅', '客房', '温馨', '时尚', '房', '布置', '精美', '处处', '体现', '人性化', '理念', '酒店', '宽敞', '停车场', '休闲', '茶', '宽敞', '会议室', '还为', '提供', '精品', '早餐', '浦东', '机场', '接机', '需', '预约', '服务', '商务', '休闲', '会务', '理想', '酒店'] 93\n",
      "---{}, {} ['n', 'v', 'n', 'ns', 'n', 'ns', 'n', 'n', 'v', 'ns', 'ns', 'v', 'n', 't', 'n', 'nr', 'n', 'n', 'd', 'q', 'a', 'v', 'n', 'n', 'nr', 'n', 'n', 'a', 'n', 'f', 'vn', 'n', 'nr', 'vn', 'n', 'ns', 'a', 'n', 'n', 'nr', 'ns', 'n', 'n', 'n', 'ns', 'n', 'ns', 'n', 'ns', 'n', 'n', 'ns', 'n', 'vn', 'n', 'v', 'a', 'a', 'n', 'n', 'nr', 'n', 'nr', 'n', 'n', 'n', 'a', 'v', 'v', 'n', 'n', 'n', 'a', 'n', 'v', 'n', 'a', 'n', 'c', 'v', 'n', 'n', 'ns', 'n', 'n', 'v', 'v', 'vn', 'n', 'v', 'n', 'n', 'n'] 93\n",
      "---{}, {} ['开业', '间房', '上海', '万信', '酒店', '位于', '浦东新区', '山路', '地处', '内环线', '陆家嘴', '金融', '区内', '近', '地铁', '号线', '北洋', '泾路', '站', '地铁', '号线', '芳甸', '路站', '配备', '专属', '停车场', '自驾', '新', '国际博览', '中心', '约', '分钟', '外滩', '世博园', '区', '南京路', '步行街', '上海', '自由贸易区', '上海', '迪斯尼乐园', '约', '分钟', '酒店', '拥有', '客房', '精选', '配套', '舒适', '相拥', '酒店', '餐厅', '环境', '舒适安逸', '主打', '西餐', '辅以', '粤菜', '川菜', '沪菜', '享受', '名厨', '精心', '烹饪', '佳肴', '舌尖', '跳起', '芭蕾', '早餐', '菜品', '可达', '保证', '口味', '餐品', '均', '选', '优质', '食材', '当天', '加工', '酒店', '豪华', '宴会厅', '提供', '婚礼', '服务', '专业', '会务', '服务', '信厅', '支持', '约', '课桌', '会议', '丽都', '厅', '适合', '以下', '各类', '会议', '需求', '万信', '酒店设计', '突破', '万信', '酒店', '理念', '时尚', '年轻', '秉承', '文化', '华丽', '贴心', '轻松', '享受'] 115\n",
      "---{}, {} ['n', 'n', 'ns', 'nz', 'n', 'v', 'ns', 'n', 's', 'n', 'nr', 'n', 's', 'a', 'n', 'n', 'ns', 'ns', 'v', 'n', 'n', 'n', 'n', 'v', 'n', 'n', 'v', 'a', 'n', 'n', 'd', 'q', 'n', 'nr', 'n', 'ns', 'n', 'ns', 'nt', 'ns', 'ns', 'd', 'q', 'n', 'v', 'n', 'v', 'a', 'a', 'v', 'n', 'n', 'n', 'nr', 'n', 'n', 'v', 'n', 'n', 'n', 'v', 'n', 'n', 'v', 'n', 'n', 'v', 'n', 'n', 'n', 'v', 'v', 'n', 'n', 'd', 'v', 'n', 'n', 't', 'vn', 'n', 'a', 'n', 'v', 'n', 'vn', 'n', 'n', 'vn', 'n', 'v', 'd', 'n', 'n', 'ns', 'n', 'v', 'f', 'r', 'n', 'v', 'nz', 'n', 'vn', 'nz', 'n', 'n', 'n', 'a', 'v', 'n', 'nr', 'v', 'a', 'v'] 115\n",
      "---{}, {} ['开业', '装修', '间房', '酒店', '位于', '浦东新区', '南', '公路', '弄', '素有', '上海', '称', '周浦镇', '南', '公路', '横桥', '路', '路口', '周边', '地铁', '线', '周', '浦东', '站', '线', '沿路', '站', '号线', '直达', '海洋公园', '冰雪', '世界', '游玩', '景点', '号线', '直达', '迪士尼', '乐园', '毗邻', '迪士尼', '乐园', '新', '国际博览', '中心', '酒店', '周围', '迪士尼', '上海', '动物园', '海昌', '海洋', '世界', '上海', '科技馆', '游玩', '景点', '周边', '更', '万达', '广场', '绿地', '商城', '美食', '娱乐', '均', '轻松', '满足', '酒店', '美国', '著名', '设计师', '打造', '知名', '高端', '设计师', '酒店', '品牌', '客房', '典雅', '豪华', '宽敞', '舒适', '配以', '飞利浦', '电视', '三诺', '音响', '电动', '窗帘', '智能', '灯', '控系统', '先进', '科技', '设施', '设备', '带来', '尊贵', '体验', '高端', '享受', '酒店', '每个', '房间', '独立', '企业级', '带给', '网络', '极速', '体验', '隔音', '系统', '更', '清华', '声学', '设计', '睡眠', '环境', '优越', '酣眠', '酒店', '提供', '浦东国际机场', '迪士尼', '周', '浦东', '站', '定时', '免费', '班车', '服务', '请', '提前', '致电', '酒店', '前台', '预约', '详情请', '咨询', '店家'] 140\n",
      "---{}, {} ['n', 'v', 'n', 'n', 'v', 'ns', 'ns', 'n', 'v', 'v', 'ns', 'v', 'nr', 'ns', 'n', 'ns', 'n', 's', 'f', 'n', 'n', 'nr', 'ns', 'v', 'n', 'n', 'v', 'n', 'v', 'n', 'n', 'n', 'n', 'n', 'n', 'v', 'nr', 'n', 'v', 'nr', 'n', 'a', 'n', 'n', 'n', 'f', 'nr', 'ns', 'n', 'ns', 'ns', 'n', 'ns', 'n', 'n', 'n', 'f', 'd', 'nz', 'n', 'n', 'ns', 'n', 'vn', 'd', 'a', 'v', 'n', 'ns', 'a', 'n', 'v', 'v', 'n', 'n', 'n', 'n', 'n', 'a', 'a', 'a', 'a', 'v', 'nz', 'n', 'nz', 'n', 'n', 'n', 'n', 'n', 'n', 'a', 'n', 'n', 'vn', 'v', 'a', 'n', 'n', 'v', 'n', 'r', 'n', 'v', 'n', 'v', 'n', 'd', 'n', 'n', 'n', 'd', 'nz', 'n', 'vn', 'v', 'n', 'a', 'v', 'n', 'v', 'nt', 'nr', 'nr', 'ns', 'v', 'd', 'vn', 'n', 'vn', 'v', 'v', 'v', 'n', 'n', 'v', 'v', 'vn', 'n'] 140\n",
      "++++++++{} ['开业', '间房', '上海', '时生隅', '园林', '文化', '酒店', '秋末', '时生隅', '初见', '心愿', '想要', '快节奏', '都市', '讲诉', '时光', '生命', '角落', '对错', '闻', '浮沉', '便是', '时生隅', '由来', '秉承', '初心', '川沙', '地铁站', '商圈', '觅得', '天地', '充满', '江南', '气息', '园林', '叶园', '长廊', '湖景', '古雅', '庭院', '大气', '快节奏', '民俗文化', '交融', '幽静', '明快', '小憩', '居', '别样', '天地', '时生隅', '新老朋友', '叶园', '期待', '共', '当下', '时光', '言欢', '开业', '装修', '间', '房云', '夜泊', '酒店', '上海浦东国际机场', '店', '位于', '浦东新区', '祝桥秋亭', '路', '毗邻', '上海浦东国际机场', '车程', '分钟', '上海', '迪士尼', '分钟', '车程', '上海', '动物园', '分钟', '车程', '酒店', '地理位置', '优越', '配备', '大巴', '中巴', '豪华轿车', '接送', '客户', '酒店', '拥有', '房间', '床', '间', '行政', '大床', '间', '标间', '间亲', '子房', '间', '开业', '装修', '间房', '维也纳', '酒店', '上海浦东', '机场', '店', '位于', '浦东新区', '川南', '奉', '公路', '近晨', '阳路', '迪士尼', '直线', '距离', '约', '公里', '便捷', '到达', '地铁', '号线', '凌空', '路站', '交通', '便利', '酒店', '周围', '生活', '设施', '齐全', '旅游', '资源', '上海', '新', '国际博览', '中心', '迪士尼', '上海', '动物园', '农艺', '大观园', '滨海', '旅游区', '维也纳', '酒店', '上海浦东', '机场', '店', '维也纳', '旗下', '连锁', '酒店', '装修', '豪华', '舒适', '整体', '风格', '高贵典雅', '客房', '温馨', '时尚', '房', '布置', '精美', '处处', '体现', '人性化', '理念', '酒店', '宽敞', '停车场', '休闲', '茶', '宽敞', '会议室', '还为', '提供', '精品', '早餐', '浦东', '机场', '接机', '需', '预约', '服务', '商务', '休闲', '会务', '理想', '酒店', '开业', '间房', '上海', '万信', '酒店', '位于', '浦东新区', '山路', '地处', '内环线', '陆家嘴', '金融', '区内', '近', '地铁', '号线', '北洋', '泾路', '站', '地铁', '号线', '芳甸', '路站', '配备', '专属', '停车场', '自驾', '新', '国际博览', '中心', '约', '分钟', '外滩', '世博园', '区', '南京路', '步行街', '上海', '自由贸易区', '上海', '迪斯尼乐园', '约', '分钟', '酒店', '拥有', '客房', '精选', '配套', '舒适', '相拥', '酒店', '餐厅', '环境', '舒适安逸', '主打', '西餐', '辅以', '粤菜', '川菜', '沪菜', '享受', '名厨', '精心', '烹饪', '佳肴', '舌尖', '跳起', '芭蕾', '早餐', '菜品', '可达', '保证', '口味', '餐品', '均', '选', '优质', '食材', '当天', '加工', '酒店', '豪华', '宴会厅', '提供', '婚礼', '服务', '专业', '会务', '服务', '信厅', '支持', '约', '课桌', '会议', '丽都', '厅', '适合', '以下', '各类', '会议', '需求', '万信', '酒店设计', '突破', '万信', '酒店', '理念', '时尚', '年轻', '秉承', '文化', '华丽', '贴心', '轻松', '享受', '开业', '装修', '间房', '酒店', '位于', '浦东新区', '南', '公路', '弄', '素有', '上海', '称', '周浦镇', '南', '公路', '横桥', '路', '路口', '周边', '地铁', '线', '周', '浦东', '站', '线', '沿路', '站', '号线', '直达', '海洋公园', '冰雪', '世界', '游玩', '景点', '号线', '直达', '迪士尼', '乐园', '毗邻', '迪士尼', '乐园', '新', '国际博览', '中心', '酒店', '周围', '迪士尼', '上海', '动物园', '海昌', '海洋', '世界', '上海', '科技馆', '游玩', '景点', '周边', '更', '万达', '广场', '绿地', '商城', '美食', '娱乐', '均', '轻松', '满足', '酒店', '美国', '著名', '设计师', '打造', '知名', '高端', '设计师', '酒店', '品牌', '客房', '典雅', '豪华', '宽敞', '舒适', '配以', '飞利浦', '电视', '三诺', '音响', '电动', '窗帘', '智能', '灯', '控系统', '先进', '科技', '设施', '设备', '带来', '尊贵', '体验', '高端', '享受', '酒店', '每个', '房间', '独立', '企业级', '带给', '网络', '极速', '体验', '隔音', '系统', '更', '清华', '声学', '设计', '睡眠', '环境', '优越', '酣眠', '酒店', '提供', '浦东国际机场', '迪士尼', '周', '浦东', '站', '定时', '免费', '班车', '服务', '请', '提前', '致电', '酒店', '前台', '预约', '详情请', '咨询', '店家']\n"
     ]
    }
   ],
   "source": [
    "# 分词\n",
    "words_ls = []\n",
    "words_speech = []\n",
    "# 将texts每个item的句子拆成单词\n",
    "# jieba.enable_paddle() #启动paddle模式\n",
    "whole_words = []\n",
    "for text in texts:\n",
    "    temp_words = [w.word for w in jp.cut(text,use_paddle=True) if w.flag in flags and w.word not in stopWords and len(w.word) > 0]\n",
    "    temp_speechs = [w.flag for w in jp.cut(text,use_paddle=True) if w.flag in flags and w.word not in stopWords and len(w.word) > 0]\n",
    "#     words = [w.word for w in jp.cut(text) if w.flag in flags and w.word not in stopwords and len(w.word) > 0]\n",
    "    print('---{}, {}',temp_words, len(temp_words))\n",
    "    print('---{}, {}',temp_speechs, len(temp_speechs))\n",
    "    if len(temp_words) > 0:\n",
    "        words_ls.append(temp_words)\n",
    "        words_speech.append(temp_speechs)\n",
    "        whole_words.extend(temp_words)\n",
    "print('++++++++{}', whole_words)\n",
    "# for w in jp.cut(text,use_paddle=True):\n",
    "#天安门 ns  其中天安门用w.word   ns用w.flag\n",
    "#     print('---{}',w)\n",
    "# 构造词典 这个词典是将拼接后的文本放进去，每项都是唯一的。试验下来可以去重\n",
    "dictionary = corpora.Dictionary(words_ls)\n",
    "# for i in dictionary:\n",
    "#     print('_+_+_+_+_+_+{}', i)\n",
    "# 基于词典，使【词】→【稀疏向量】，并将向量放入列表，形成【稀疏向量集】\n",
    "#这里就是创建每个句子的词组的词频\n",
    "corpus = [dictionary.doc2bow(words) for words in words_ls]\n",
    "# print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda模型，num_topics设置主题的个数\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=10)\n",
    "# 打印所有主题，每个主题显示5个词\n",
    "for topic in lda.print_topics(num_words=10, num_topics=10):\n",
    "    print(topic)\n",
    "# 主题推断\n",
    "# print(lda.inference(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, values in enumerate(lda.inference(corpus)[0]):\n",
    "    print(texts[e])\n",
    "    for ee, value in enumerate(values):\n",
    "        print('\\t主题%d推断值%.2f' % (ee, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = '2013年开业74间房。海友酒店（上海德平路地铁站店）位于浦东新区德平路，毗邻上海八佰伴、陆家嘴、世纪公园、金桥国际商业中心。酒店附近多部公交与地铁可通往人民广场、外滩、南京路步行街等繁华商业区及旅游景点，交通便捷。 　　海友酒店（上海德平路地铁站店）拥有大床房、家庭房、双床房等多种房型供您选择，可满足顾客不同的入住需求。客房内配有24小时热水、液晶电视机等完善的配套设施，温馨舒适。 　　海友客栈（上海德平路店）竭诚为您提供至善至美的上佳服务，欢迎您随时光临下榻。'\n",
    "# bow = dictionary.doc2bow([word.word for word in jp.cut(text5) if word.flag in flags and word.word not in stopwords])\n",
    "bow = dictionary.doc2bow([w.word for w in jp.cut(text,use_paddle=True) if w.flag in flags and w.word not in stopWords and len(w.word) > 0])\n",
    "ndarray = lda.inference([bow])[0]\n",
    "print(text5)\n",
    "for e, value in enumerate(ndarray[0]):\n",
    "    print('\\t主题%d推断值%.2f' % (e, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_id = dictionary.doc2idx(['开业'])[0]\n",
    "print(dictionary.doc2idx(['开业'])[0])\n",
    "for i in lda.get_term_topics(word_id):\n",
    "    print('【开业】与【主题%d】的关系值：%.2f%%' % (i[0], i[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, word_id in dictionary.token2id.items():\n",
    "    print(word, lda.get_term_topics(word_id, minimum_probability=1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda.show_topic(0, 9999))\n",
    "print('概率总和', sum(i[1] for i in lda.show_topic(0, 9999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dictionary.token2id\n",
    "print(vocab)\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "# print(char2idx)\n",
    "idx2char = {u:i for u, i in enumerate(vocab)}\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 设定每个输入句子长度的最大值\n",
    "seq_length = 60\n",
    "examples_per_epoch = len(whole_words)//seq_length\n",
    "text_as_int = np.array([char2idx[c] for c in whole_words])\n",
    "print(text_as_int)\n",
    "# 创建训练样本 / 目标\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(list(set(whole_words)))\n",
    "word_indices = dict((word, words.index(word)) for word in words)\n",
    "print(words)\n",
    "print(word_indices)\n",
    "\n",
    "maxlen = 30\n",
    "sentences = []\n",
    "next_word = []\n",
    "\n",
    "for i in range(0, len(whole_words) - maxlen):\n",
    "    sentences.append(whole_words[i: i + maxlen])\n",
    "    next_word.append(whole_words[i + maxlen])\n",
    "print('提取的句子总数:', len(sentences))\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen), dtype='float32') # Embedding的输入是2维张量（句子数，序列长度）\n",
    "y = np.zeros((len(sentences)), dtype='float32')\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, word in enumerate(sentence):\n",
    "        x[i, t] = word_indices[word]\n",
    "    y[i] = word_indices[next_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(np.round((sys.getsizeof(x) / 1024 / 1024 / 1024), 4), \"GB\") \n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "main_input = tf.keras.layers.Input(shape=(maxlen, ), dtype='float32') \n",
    "model_1 = tf.keras.layers.Embedding(len(words), maxlen, input_length=maxlen)(main_input)\n",
    "model_1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(maxlen, return_sequences=True))(model_1)\n",
    "model_1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(maxlen))(model_1)\n",
    "output = tf.keras.layers.Dense(len(words), activation='softmax')(model_1)  \n",
    "model = tf.keras.models.Model(main_input, output)\n",
    "# optimizer = tf.keras.optimizers.RMSprop(lr=3e-3)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# 检查点保存至的目录\n",
    "checkpoint_dir = './ldatraining_checkpoints'\n",
    "\n",
    "# 检查点的文件名\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=10, batch_size=1024, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 100\n",
    "    input_eval = [char2idx[s.word] for s in jp.cut(start_string)]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    # 空字符串用于存储结果\n",
    "    text_generated = []\n",
    "\n",
    "    # 低温度会生成更可预测的文本\n",
    "    # 较高温度会生成更令人惊讶的文本\n",
    "    # 可以通过试验以找到最好的设定\n",
    "    temperature = 1.0\n",
    "\n",
    "    # 这里批大小为 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        print(predictions)\n",
    "        # 删除批次的维度\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        print(predictions)\n",
    "        # 用分类分布预测模型返回的字符\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # 把预测字符和前面的隐藏状态一起传递给模型作为下一个输入\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(model, start_string=u\"酒店服务\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
